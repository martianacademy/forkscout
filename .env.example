# Forkscout Environment Configuration

# ── Global LLM Config ────────────────────────────────────
# Default provider used when no per-tier provider is set
LLM_PROVIDER=openrouter
LLM_MODEL=x-ai/grok-4.1-fast
LLM_BASE_URL=https://openrouter.ai/api/v1
LLM_API_KEY=

# Temperature (0-1, higher = more creative)
LLM_TEMPERATURE=0.7
LLM_MAX_TOKENS=2000

# ── Provider API Keys ────────────────────────────────────
# Add all your API keys here. The router auto-picks the right key
# based on each tier's provider. You only pay for what you use.
OPENROUTER_API_KEY=
OPENAI_API_KEY=
ANTHROPIC_API_KEY=
GOOGLE_API_KEY=

# ── Multi-Model Router ──────────────────────────────────
# Three tiers: fast (cheap), balanced (daily driver), powerful (complex tasks)
# Each tier auto-selects the right API key from the provider keys above.
MODEL_FAST=google/gemini-2.0-flash-001
MODEL_BALANCED=x-ai/grok-4.1-fast
MODEL_POWERFUL=anthropic/claude-sonnet-4
BUDGET_DAILY_USD=5
BUDGET_MONTHLY_USD=50

# ── Per-Tier Provider Override (optional) ────────────────
# Override the provider for individual tiers.
# If set, the router uses that provider's API key from above automatically.
# Supported: openrouter, openai, anthropic, google, ollama, openai-compatible
#
# Example: fast=Google direct, balanced=OpenRouter, powerful=Anthropic direct
# MODEL_FAST_PROVIDER=google
# MODEL_BALANCED_PROVIDER=openrouter
# MODEL_POWERFUL_PROVIDER=anthropic
#
# Per-tier API key/URL overrides (rarely needed — keys auto-resolve from above)
# MODEL_FAST_API_KEY=
# MODEL_FAST_BASE_URL=

# For running inside Docker with host Ollama:
# LLM_BASE_URL=http://host.docker.internal:11434/v1

# SearXNG URL for web search tool
SEARXNG_URL=http://localhost:8888

# Agent configuration
AGENT_MAX_ITERATIONS=10
AGENT_AUTO_REGISTER_TOOLS=true

ADMIN_SECRET=

# Telegram Bot (optional — set to enable Telegram bridge)
TELEGRAM_BOT_TOKEN=
